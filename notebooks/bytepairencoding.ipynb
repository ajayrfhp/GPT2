{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajayrfhp/LearningDeepLearning/blob/main/bytepairencoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44FPA2fwh2l5"
      },
      "source": [
        "# Bytepair encoding\n",
        "- Goal is to reimplement bytepair encoding from scratch and have output match with the tiktoken library\n",
        "\n",
        "## GPT2 tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input string: Hello, world!\n",
            "GPT-2 tokenized: [15496, 11, 995, 0]\n",
            "GPT-2 tokenized intermediate: ['Hello', ',', ' world', '!']\n",
            "GPT-2 tokenized decoded: Hello, world!\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "\n",
        "input_str = \"Hello, world!\"\n",
        "gpt2_tokenizer = tiktoken.encoding_for_model(\"gpt-2\")\n",
        "gpt2_tokenized = gpt2_tokenizer.encode(input_str)\n",
        "gpt2_tokenized_intermediate = [gpt2_tokenizer.decode([token]) for token in gpt2_tokenized]\n",
        "gpt2_tokenized_decoded = gpt2_tokenizer.decode(gpt2_tokenized)\n",
        "\n",
        "print(\"Input string:\", input_str)\n",
        "print(\"GPT-2 tokenized:\", gpt2_tokenized)\n",
        "print(\"GPT-2 tokenized intermediate:\", gpt2_tokenized_intermediate)\n",
        "print(\"GPT-2 tokenized decoded:\", gpt2_tokenized_decoded)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- GPT 2 tokenizer has 50,000 merges and 256 unicode characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50257"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gpt2_tokenizer.n_vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Implementation from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prepare vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fRg3WCvahsOL",
        "outputId": "b2a041fd-6b68-41e3-c24c-6080962378d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "max_vocab_size = 50257\n",
        "\n",
        "\n",
        "def init_vocab():\n",
        "  vocab = {}\n",
        "  vocab_size = 0\n",
        "\n",
        "  for chr_code in range(256):\n",
        "    vocab[chr_code] = chr(chr_code)\n",
        "    vocab_size += 1\n",
        "  return vocab, vocab_size\n",
        "\n",
        "vocab, vocab_size = init_vocab()\n",
        "len(vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get pair count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VffNrD9NiIh5",
        "outputId": "c9250410-3197-4ef8-ab68-958a19385bd4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(72, 101)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_pair_count(text, counts=defaultdict(int)):\n",
        "  most_frequent_pair = None\n",
        "  most_frequent_pair_count = 0\n",
        "  for i in range(len(text)-1):\n",
        "    pair = tuple(text[i:i+2])\n",
        "    counts[pair] += 1\n",
        "    if counts[pair] > most_frequent_pair_count:\n",
        "      most_frequent_pair = pair\n",
        "      most_frequent_pair_count = counts[pair]\n",
        "  return counts, most_frequent_pair, most_frequent_pair_count\n",
        "\n",
        "text = \"Hello, world!\"\n",
        "text_encoded = text.encode('utf-8')\n",
        "pair_count, most_frequent_pair, most_frequent_pair_count = get_pair_count(text_encoded)\n",
        "most_frequent_pair"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-8TdZo3_EyH"
      },
      "source": [
        "- Merge common tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "R8pH099Xiuo_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12\n",
            "9\n"
          ]
        }
      ],
      "source": [
        "# Add symbol for most frequent pair in vocab and run encoding again to replace most frequent pair with new symbol.\n",
        "\n",
        "def merge(text_encoded, pair, idx):\n",
        "  i = 0\n",
        "  text_encoded_merged = []\n",
        "  while i < len(text_encoded) - 1:\n",
        "    if not text_encoded[i]:\n",
        "      continue\n",
        "    elif text_encoded[i] == pair[0] and text_encoded[i+1] == pair[1]:\n",
        "      text_encoded_merged.append(idx)\n",
        "      i += 2\n",
        "    else:\n",
        "      text_encoded_merged.append(text_encoded[i])\n",
        "      i += 1\n",
        "  return text_encoded_merged\n",
        "\n",
        "text_encoded=[1, 2, 3, 4, 5, 5, 1, 2, 9,  9, 1, 2]\n",
        "print(len(text_encoded))\n",
        "text_encoded = merge(\n",
        "    text_encoded,\n",
        "    pair=[1, 2],\n",
        "    idx=10\n",
        ")\n",
        "print(len(text_encoded))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(72, 101)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from collections import Counter\n",
        "def get_pair_countv2(text):\n",
        "    pair_iterator = zip(text, text[1:])\n",
        "    counts = Counter(pair_iterator)\n",
        "    most_frequent_pair = counts.most_common(1)\n",
        "    return counts, most_frequent_pair[0][0], most_frequent_pair[0][1]\n",
        "\n",
        "text = \"Hello, world!\"\n",
        "text_encoded = text.encode('utf-8')\n",
        "pair_count, most_frequent_pair, most_frequent_pair_count = get_pair_countv2(text_encoded)\n",
        "most_frequent_pair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[10, 3, 4, 5, 5, 10, 10]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def mergev2(text_encoded, pair, idx):\n",
        "    i = 0\n",
        "    new_text_encoded = []\n",
        "    while i < len(text_encoded):\n",
        "        if i+1 < len(text_encoded) and text_encoded[i] == pair[0] and text_encoded[i+1] == pair[1]:\n",
        "            new_text_encoded.append(idx)\n",
        "            i += 2\n",
        "        else:\n",
        "            new_text_encoded.append(text_encoded[i])\n",
        "            i += 1\n",
        "    del text_encoded\n",
        "    return new_text_encoded\n",
        "\n",
        "mergev2(\n",
        "    text_encoded=[1, 2, 3, 4, 5, 5, 1, 2, 1, 2],\n",
        "    pair=[1, 2],\n",
        "    idx=10\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Had copilot rewrite the above functions in cython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext Cython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%cython\n",
        "\n",
        "from collections import defaultdict\n",
        "import cython # Allows using @cython decorators if needed, and type hints\n",
        "\n",
        "# cpdef makes the function available to Python and optimized for C calls\n",
        "# We type inputs/outputs. Assuming 'data' is bytes as in BPE context.\n",
        "# Returns a Python tuple: (dict, tuple | None, int)\n",
        "cpdef tuple get_paircountv3(list data):\n",
        "\n",
        "    # --- C Type Declarations ---\n",
        "    cdef Py_ssize_t i, n\n",
        "    cdef int p0, p1\n",
        "    cdef int count, max_count = 0\n",
        "    cdef tuple pair_key\n",
        "    cdef tuple max_pair = None\n",
        "    counts = defaultdict(int)\n",
        "    # ---------------------------\n",
        "\n",
        "    n = len(data)\n",
        "\n",
        "    if n < 2:\n",
        "        return counts, None, 0\n",
        "\n",
        "    # --- Counting Loop ---\n",
        "    for i in range(n - 1):\n",
        "        p0 = data[i]\n",
        "        p1 = data[i+1]\n",
        "        pair_key = (p0, p1)\n",
        "        counts[pair_key] += 1\n",
        "    # ---------------------\n",
        "\n",
        "    # --- Find Maximum After Loop ---\n",
        "    # Iterate using the standard .items() method\n",
        "    for pair_key, count in counts.items(): # CORRECTED LINE\n",
        "        if count > max_count:\n",
        "            max_count = count\n",
        "            max_pair = pair_key\n",
        "    # ---------------------------\n",
        "\n",
        "    return counts, max_pair, max_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%cython\n",
        "\n",
        "# Import necessary types if needed (often optional for basic types)\n",
        "# cimport cython # Uncomment if using @cython decorators later\n",
        "\n",
        "# Use 'cpdef' for a function callable from both Python and C (Cython) code\n",
        "# Add type declarations for variables using 'cdef' and in the signature\n",
        "# We assume inputs are Python lists/int, output is Python list\n",
        "# Typing loop variables (i, n) and known types (idx) gives most benefit here\n",
        "cpdef list mergev3(list original_text_encoded, tuple pair_to_replace, int replacement_idx):\n",
        "    # --- C variable declarations ---\n",
        "    cdef Py_ssize_t i = 0  # Py_ssize_t is preferred for indexing\n",
        "    cdef Py_ssize_t n = len(original_text_encoded)\n",
        "    cdef list new_list = [] # Output remains a standard Python list\n",
        "    # Assume pair elements are integers for comparison\n",
        "    # Type checking happens when accessing pair_to_replace[0]\n",
        "    cdef int p0 = pair_to_replace[0]\n",
        "    cdef int p1 = pair_to_replace[1]\n",
        "    # ------------------------------\n",
        "\n",
        "    while i < n:\n",
        "        # Accessing list elements (original_text_encoded[i]) still involves\n",
        "        # Python object overhead as it's a Python list.\n",
        "        # For max speed, inputs would ideally be memoryviews or arrays.\n",
        "        if i + 1 < n and original_text_encoded[i] == p0 and original_text_encoded[i+1] == p1:\n",
        "            new_list.append(replacement_idx) # Append the typed int\n",
        "            i += 2\n",
        "        else:\n",
        "            new_list.append(original_text_encoded[i]) # Append existing Python object\n",
        "            i += 1\n",
        "\n",
        "    # No need for 'del text_encoded' as the original list wasn't modified\n",
        "    return new_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqkZgltiGShu"
      },
      "source": [
        "Grab big text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oce4qDNuF5Jn",
        "outputId": "ed7b8233-820f-4b20-b370-f0a7c05fc88b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "220288"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import requests\n",
        "import regex as re\n",
        "big_text_url = \"https://raw.githubusercontent.com/dscape/spell/refs/heads/master/test/resources/big.txt\"\n",
        "\n",
        "big_text = requests.get(big_text_url).text\n",
        "big_text = big_text[:1000000]\n",
        "gpt2_pattern = r\"\"\"'(?:[sdmt]|ll|ve|re)| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"\n",
        "compiled_pattern = re.compile(gpt2_pattern)\n",
        "big_text = re.findall(compiled_pattern, big_text)\n",
        "big_text_encoded = [ list(chunk.encode(\"utf-8\")) for chunk in big_text]\n",
        "\n",
        "len(big_text_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[84, 104, 101]"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "big_text_encoded[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Let's do 10 merges and profile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPi_poCuHlfv",
        "outputId": "6aca98b7-9679-41cb-8e21-3c23d8097dd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The line_profiler extension is already loaded. To reload it, use:\n",
            "  %reload_ext line_profiler\n",
            "merge 0 (32, 116) to  t\n",
            "merge 1 (276, 104) to Ĕh\n",
            "merge 2 (32, 97) to  a\n",
            "merge 3 (32, 115) to  s\n",
            "merge 4 (32, 99) to  c\n",
            "merge 5 (32, 32) to   \n",
            "merge 6 (32, 112) to  p\n",
            "merge 7 (32, 105) to  i\n",
            "merge 8 (281, 281) to ęę\n",
            "merge 9 (284, 284) to ĜĜ\n",
            "merge 10 (280, 111) to Ęo\n",
            "merge 11 (32, 67) to  C\n",
            "merge 12 (32, 77) to  M\n",
            "merge 13 (32, 114) to  r\n",
            "merge 14 (32, 82) to  R\n",
            "merge 15 (32, 117) to  u\n",
            "merge 16 (10, 10) to \n",
            "\n",
            "\n",
            "merge 17 (32, 100) to  d\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 11.2314 s\n",
            "File: /tmp/ipykernel_2290/1040820679.py\n",
            "Function: profile_merge at line 4\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     4                                           def profile_merge(vocab, big_text_encoded_local, vocab_size):\n",
            "     5         1       1300.0   1300.0      0.0    num_merges = vocab_size - 256\n",
            "     6        21      15700.0    747.6      0.0    for i in range(num_merges):\n",
            "     7        20       5600.0    280.0      0.0      most_frequent_pair = None \n",
            "     8        20       3300.0    165.0      0.0      most_frequent_pair_count = 0\n",
            "     9        20     266100.0  13305.0      0.0      counts = defaultdict(int)\n",
            "    10   4405780  654318800.0    148.5      5.8      for chunk in big_text_encoded_local:\n",
            "    11   4405760 4655131100.0   1056.6     41.4        counts, chunk_most_frequent_pair, chunk_most_frequent_pair_count = get_pair_count(chunk, counts)\n",
            "    12   4405760  659914100.0    149.8      5.9        if chunk_most_frequent_pair_count > most_frequent_pair_count:\n",
            "    13     69848    9469100.0    135.6      0.1          most_frequent_pair = chunk_most_frequent_pair\n",
            "    14     69848    9324000.0    133.5      0.1          most_frequent_pair_count = chunk_most_frequent_pair_count\n",
            "    15        20      18700.0    935.0      0.0      if most_frequent_pair:\n",
            "    16        18 5240622900.0    3e+08     46.7        big_text_encoded_local= [merge(chunk, most_frequent_pair, vocab_size) for chunk in big_text_encoded_local]\n",
            "    17        18      34300.0   1905.6      0.0        vocab_size += 1\n",
            "    18        18     141300.0   7850.0      0.0        vocab[vocab_size] = ''.join(map(chr, most_frequent_pair))\n",
            "    19        18    2159200.0 119955.6      0.0        print(f\"merge {i} {most_frequent_pair} to {vocab[vocab_size]}\")\n",
            "    20                                           \n",
            "    21         1        100.0    100.0      0.0    return vocab"
          ]
        }
      ],
      "source": [
        "%load_ext line_profiler\n",
        "\n",
        "\n",
        "def profile_merge(vocab, big_text_encoded_local, vocab_size):\n",
        "  num_merges = vocab_size - 256\n",
        "  for i in range(num_merges):\n",
        "    most_frequent_pair = None \n",
        "    most_frequent_pair_count = 0\n",
        "    counts = defaultdict(int)\n",
        "    for chunk in big_text_encoded_local:\n",
        "      counts, chunk_most_frequent_pair, chunk_most_frequent_pair_count = get_pair_count(chunk, counts)\n",
        "      if chunk_most_frequent_pair_count > most_frequent_pair_count:\n",
        "        most_frequent_pair = chunk_most_frequent_pair\n",
        "        most_frequent_pair_count = chunk_most_frequent_pair_count\n",
        "    if most_frequent_pair:\n",
        "      big_text_encoded_local= [merge(chunk, most_frequent_pair, vocab_size) for chunk in big_text_encoded_local]\n",
        "      vocab_size += 1\n",
        "      vocab[vocab_size] = ''.join(map(chr, most_frequent_pair))\n",
        "      print(f\"merge {i} {most_frequent_pair} to {vocab[vocab_size]}\")\n",
        "\n",
        "  return vocab\n",
        "\n",
        "\n",
        "vocab, vocab_size = init_vocab()\n",
        "\n",
        "%lprun -f profile_merge profile_merge(vocab, big_text_encoded.copy(), vocab_size=276)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(big_text_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The line_profiler extension is already loaded. To reload it, use:\n",
            "  %reload_ext line_profiler\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "'bytes' object cannot be interpreted as an integer",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[45], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmerge \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmost_frequent_pair\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvocab[vocab_size]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m vocab, vocab_size \u001b[38;5;241m=\u001b[39m init_vocab()\n\u001b[0;32m---> 14\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlprun\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-f profile_mergev2 profile_mergev2(vocab, big_text_encoded.copy(), vocab_size=276)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[0;32m~/anaconda3/envs/GPT2/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2480\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2478\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2480\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2482\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2483\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2484\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
            "File \u001b[0;32m~/anaconda3/envs/GPT2/lib/python3.11/site-packages/line_profiler/ipython_extension.py:130\u001b[0m, in \u001b[0;36mLineProfilerMagics.lprun\u001b[0;34m(self, parameter_s)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m         profile\u001b[38;5;241m.\u001b[39mrunctx(arg_str, global_ns, local_ns)\n\u001b[1;32m    131\u001b[0m         message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mSystemExit\u001b[39;00m:\n",
            "File \u001b[0;32m~/anaconda3/envs/GPT2/lib/python3.11/site-packages/line_profiler/line_profiler.py:185\u001b[0m, in \u001b[0;36mLineProfiler.runctx\u001b[0;34m(self, cmd, globals, locals)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_by_count()\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 185\u001b[0m     exec(cmd, \u001b[38;5;28mglobals\u001b[39m, \u001b[38;5;28mlocals\u001b[39m)\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable_by_count()\n",
            "File \u001b[0;32m<string>:1\u001b[0m\n",
            "Cell \u001b[0;32mIn[45], line 10\u001b[0m, in \u001b[0;36mprofile_mergev2\u001b[0;34m(vocab, big_text_encoded_local, vocab_size)\u001b[0m\n\u001b[1;32m      8\u001b[0m big_text_encoded_local \u001b[38;5;241m=\u001b[39m mergev2(big_text_encoded_local, most_frequent_pair, vocab_size)\n\u001b[1;32m      9\u001b[0m vocab_size \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 10\u001b[0m vocab[vocab_size] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mchr\u001b[39m, most_frequent_pair))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmerge \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmost_frequent_pair\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvocab[vocab_size]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mTypeError\u001b[0m: 'bytes' object cannot be interpreted as an integer"
          ]
        }
      ],
      "source": [
        "%load_ext line_profiler\n",
        "\n",
        "\n",
        "def profile_mergev2(vocab, big_text_encoded_local, vocab_size):\n",
        "  num_merges = vocab_size - 256\n",
        "  for i in range(num_merges):\n",
        "    _, most_frequent_pair, _ = get_pair_countv2(big_text_encoded_local)\n",
        "    big_text_encoded_local = mergev2(big_text_encoded_local, most_frequent_pair, vocab_size)\n",
        "    vocab_size += 1\n",
        "    vocab[vocab_size] = ''.join(map(chr, most_frequent_pair))\n",
        "    print(f\"merge {i} {most_frequent_pair} to {vocab[vocab_size]}\")\n",
        "\n",
        "vocab, vocab_size = init_vocab()\n",
        "%lprun -f profile_mergev2 profile_mergev2(vocab, big_text_encoded.copy(), vocab_size=276)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(big_text_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext line_profiler\n",
        "\n",
        "\n",
        "def profile_mergev3(vocab, big_text_encoded_local, vocab_size):\n",
        "  num_merges = vocab_size - 256\n",
        "  for i in range(num_merges):\n",
        "    _, most_frequent_pair, _ = get_paircountv3(big_text_encoded_local)\n",
        "    big_text_encoded_local = mergev3(big_text_encoded_local, most_frequent_pair, vocab_size)\n",
        "    vocab_size += 1\n",
        "    vocab[vocab_size] = ''.join(map(chr, most_frequent_pair))\n",
        "    if i % 100 == 0:\n",
        "      print(f\"merge {i} {most_frequent_pair} to {vocab[vocab_size]}\")\n",
        "  return vocab\n",
        "  \n",
        "\n",
        "vocab, vocab_size = init_vocab()\n",
        "%lprun -f profile_mergev3 profile_mergev3(vocab, big_text_encoded.copy(), vocab_size=276)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab, vocab_size = init_vocab()\n",
        "vocab = profile_mergev3(vocab, big_text_encoded, vocab_size=1257)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnAEaJPULOnL",
        "outputId": "6b81fd07-c96e-4c6a-8efe-77255d1f60b2"
      },
      "outputs": [],
      "source": [
        "reverse_vocab = {v: k for k, v in vocab.items()}\n",
        "max_token_size = max(map(len, reverse_vocab.keys()))\n",
        "max_token_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmARh_4gIg1A",
        "outputId": "bdb90dd5-75ca-45dc-dc64-e01c18077305"
      },
      "outputs": [],
      "source": [
        "def encode(text, reverse_vocab):\n",
        "  i = 0\n",
        "  text_encoded = []\n",
        "  while i < len(text):\n",
        "    for j in range(max_token_size, 0, -1):\n",
        "      potential_token = text[i:i+j]\n",
        "      if potential_token in reverse_vocab:\n",
        "        text_encoded.append(reverse_vocab[potential_token])\n",
        "        i += j\n",
        "        break\n",
        "  return text_encoded\n",
        "\n",
        "\n",
        "def decode(text_encoded, vocab):\n",
        "  text = \"\"\n",
        "  text_list = []\n",
        "  for code in text_encoded:\n",
        "    text += vocab[code]\n",
        "    text_list.append(vocab[code])\n",
        "  return text, text_list\n",
        "\n",
        "encoded_text = encode(\"Hello this is Ajay\", reverse_vocab)\n",
        "print(encoded_text)\n",
        "decoded_text, decoded_text_list = decode(encoded_text, vocab)\n",
        "print(decoded_text)\n",
        "print(decoded_text_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBVEPgODMv5-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOh1z8AfU1msFyB1A9Q2YbC",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "GPT2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
