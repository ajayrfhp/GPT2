{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajayrfhp/LearningDeepLearning/blob/main/bytepairencoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44FPA2fwh2l5"
      },
      "source": [
        "# Bytepair encoding\n",
        "- Goal is to reimplement bytepair encoding from scratch and have output match with the tiktoken library\n",
        "\n",
        "## GPT2 tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input string: Hello, world!\n",
            "GPT-2 tokenized: [15496, 11, 995, 0]\n",
            "GPT-2 tokenized intermediate: ['Hello', ',', ' world', '!']\n",
            "GPT-2 tokenized decoded: Hello, world!\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "\n",
        "input_str = \"Hello, world!\"\n",
        "gpt2_tokenizer = tiktoken.encoding_for_model(\"gpt-2\")\n",
        "gpt2_tokenized = gpt2_tokenizer.encode(input_str)\n",
        "gpt2_tokenized_intermediate = [gpt2_tokenizer.decode([token]) for token in gpt2_tokenized]\n",
        "gpt2_tokenized_decoded = gpt2_tokenizer.decode(gpt2_tokenized)\n",
        "\n",
        "print(\"Input string:\", input_str)\n",
        "print(\"GPT-2 tokenized:\", gpt2_tokenized)\n",
        "print(\"GPT-2 tokenized intermediate:\", gpt2_tokenized_intermediate)\n",
        "print(\"GPT-2 tokenized decoded:\", gpt2_tokenized_decoded)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- GPT 2 tokenizer has 50,000 merges and 256 unicode characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50257"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gpt2_tokenizer.n_vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Implementation from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prepare vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fRg3WCvahsOL",
        "outputId": "b2a041fd-6b68-41e3-c24c-6080962378d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "max_vocab_size = 50257\n",
        "\n",
        "\n",
        "def init_vocab():\n",
        "  vocab = {}\n",
        "  vocab_size = 0\n",
        "\n",
        "  for chr_code in range(256):\n",
        "    vocab[chr_code] = chr(chr_code)\n",
        "    vocab_size += 1\n",
        "  return vocab, vocab_size\n",
        "\n",
        "vocab, vocab_size = init_vocab()\n",
        "len(vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get pair count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VffNrD9NiIh5",
        "outputId": "c9250410-3197-4ef8-ab68-958a19385bd4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(72, 101)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_pair_count(text):\n",
        "  counts = defaultdict(int)\n",
        "  most_frequent_pair = None\n",
        "  most_frequent_pair_count = 0\n",
        "  for i in range(len(text)-1):\n",
        "    pair = tuple(text[i:i+2])\n",
        "    counts[pair] += 1\n",
        "    if counts[pair] > most_frequent_pair_count:\n",
        "      most_frequent_pair = pair\n",
        "      most_frequent_pair_count = counts[pair]\n",
        "  return counts, most_frequent_pair, most_frequent_pair_count\n",
        "\n",
        "text = \"Hello, world!\"\n",
        "text_encoded = text.encode('utf-8')\n",
        "pair_count, most_frequent_pair, most_frequent_pair_count = get_pair_count(text_encoded)\n",
        "most_frequent_pair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(72, 101)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from collections import Counter\n",
        "def get_pair_countv2(text):\n",
        "    pair_iterator = zip(text, text[1:])\n",
        "    counts = Counter(pair_iterator)\n",
        "    most_frequent_pair = counts.most_common(1)\n",
        "    return counts, most_frequent_pair[0][0], most_frequent_pair[0][1]\n",
        "\n",
        "text = \"Hello, world!\"\n",
        "text_encoded = text.encode('utf-8')\n",
        "pair_count, most_frequent_pair, most_frequent_pair_count = get_pair_countv2(text_encoded)\n",
        "most_frequent_pair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "b'Hello, world!'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_encoded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-8TdZo3_EyH"
      },
      "source": [
        "- Merge common tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "R8pH099Xiuo_"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[10, 3, 4, 5, 5]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Add symbol for most frequent pair in vocab and run encoding again to replace most frequent pair with new symbol.\n",
        "\n",
        "def merge(text_encoded, pair, idx):\n",
        "  i = 0\n",
        "\n",
        "  while i < len(text_encoded) - 1:\n",
        "    if text_encoded[i] == pair[0] and text_encoded[i+1] == pair[1]:\n",
        "      text_encoded[i] = idx\n",
        "      text_encoded.pop(i+1)\n",
        "    else:\n",
        "      i += 1\n",
        "  return text_encoded\n",
        "\n",
        "merge(\n",
        "    text_encoded=[1, 2, 3, 4, 5, 5],\n",
        "    pair=[1, 2],\n",
        "    idx=10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[10, 3, 4, 5, 5]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def mergev2(text_encoded, pair, idx):\n",
        "    i = 0\n",
        "    new_text_encoded = []\n",
        "    while i < len(text_encoded):\n",
        "        if i+1 < len(text_encoded) and text_encoded[i] == pair[0] and text_encoded[i+1] == pair[1]:\n",
        "            new_text_encoded.append(idx)\n",
        "            i += 2\n",
        "        else:\n",
        "            new_text_encoded.append(text_encoded[i])\n",
        "            i += 1\n",
        "    del text_encoded\n",
        "    return new_text_encoded\n",
        "\n",
        "mergev2(\n",
        "    text_encoded=[1, 2, 3, 4, 5, 5],\n",
        "    pair=[1, 2],\n",
        "    idx=10\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Had copilot rewrite the above functions in cython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext Cython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%cython\n",
        "\n",
        "from collections import defaultdict\n",
        "import cython # Allows using @cython decorators if needed, and type hints\n",
        "\n",
        "# cpdef makes the function available to Python and optimized for C calls\n",
        "# We type inputs/outputs. Assuming 'data' is bytes as in BPE context.\n",
        "# Returns a Python tuple: (dict, tuple | None, int)\n",
        "cpdef tuple get_paircountv3(list data):\n",
        "\n",
        "    # --- C Type Declarations ---\n",
        "    cdef Py_ssize_t i, n\n",
        "    cdef int p0, p1\n",
        "    cdef int count, max_count = 0\n",
        "    cdef tuple pair_key\n",
        "    cdef tuple max_pair = None\n",
        "    counts = defaultdict(int)\n",
        "    # ---------------------------\n",
        "\n",
        "    n = len(data)\n",
        "\n",
        "    if n < 2:\n",
        "        return counts, None, 0\n",
        "\n",
        "    # --- Counting Loop ---\n",
        "    for i in range(n - 1):\n",
        "        p0 = data[i]\n",
        "        p1 = data[i+1]\n",
        "        pair_key = (p0, p1)\n",
        "        counts[pair_key] += 1\n",
        "    # ---------------------\n",
        "\n",
        "    # --- Find Maximum After Loop ---\n",
        "    # Iterate using the standard .items() method\n",
        "    for pair_key, count in counts.items(): # CORRECTED LINE\n",
        "        if count > max_count:\n",
        "            max_count = count\n",
        "            max_pair = pair_key\n",
        "    # ---------------------------\n",
        "\n",
        "    return counts, max_pair, max_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%cython\n",
        "\n",
        "# Import necessary types if needed (often optional for basic types)\n",
        "# cimport cython # Uncomment if using @cython decorators later\n",
        "\n",
        "# Use 'cpdef' for a function callable from both Python and C (Cython) code\n",
        "# Add type declarations for variables using 'cdef' and in the signature\n",
        "# We assume inputs are Python lists/int, output is Python list\n",
        "# Typing loop variables (i, n) and known types (idx) gives most benefit here\n",
        "cpdef list mergev3(list original_text_encoded, tuple pair_to_replace, int replacement_idx):\n",
        "    # --- C variable declarations ---\n",
        "    cdef Py_ssize_t i = 0  # Py_ssize_t is preferred for indexing\n",
        "    cdef Py_ssize_t n = len(original_text_encoded)\n",
        "    cdef list new_list = [] # Output remains a standard Python list\n",
        "    # Assume pair elements are integers for comparison\n",
        "    # Type checking happens when accessing pair_to_replace[0]\n",
        "    cdef int p0 = pair_to_replace[0]\n",
        "    cdef int p1 = pair_to_replace[1]\n",
        "    # ------------------------------\n",
        "\n",
        "    while i < n:\n",
        "        # Accessing list elements (original_text_encoded[i]) still involves\n",
        "        # Python object overhead as it's a Python list.\n",
        "        # For max speed, inputs would ideally be memoryviews or arrays.\n",
        "        if i + 1 < n and original_text_encoded[i] == p0 and original_text_encoded[i+1] == p1:\n",
        "            new_list.append(replacement_idx) # Append the typed int\n",
        "            i += 2\n",
        "        else:\n",
        "            new_list.append(original_text_encoded[i]) # Append existing Python object\n",
        "            i += 1\n",
        "\n",
        "    # No need for 'del text_encoded' as the original list wasn't modified\n",
        "    return new_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqkZgltiGShu"
      },
      "source": [
        "Grab big text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oce4qDNuF5Jn",
        "outputId": "ed7b8233-820f-4b20-b370-f0a7c05fc88b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1000000"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import requests\n",
        "big_text_url = \"https://raw.githubusercontent.com/dscape/spell/refs/heads/master/test/resources/big.txt\"\n",
        "\n",
        "big_text = requests.get(big_text_url).text\n",
        "big_text = big_text[:1000000]\n",
        "big_text_encoded = list(big_text.encode('utf-8'))\n",
        "len(big_text_encoded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Let's do 10 merges and profile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPi_poCuHlfv",
        "outputId": "6aca98b7-9679-41cb-8e21-3c23d8097dd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "merge 0 (101, 32) to e \n",
            "merge 1 (116, 104) to th\n",
            "merge 2 (100, 32) to d \n",
            "merge 3 (115, 32) to s \n",
            "merge 4 (116, 32) to t \n",
            "merge 5 (105, 110) to in\n",
            "merge 6 (101, 114) to er\n",
            "merge 7 (97, 110) to an\n",
            "merge 8 (44, 32) to , \n",
            "merge 9 (277, 276) to ĕĔ\n",
            "merge 10 (111, 110) to on\n",
            "merge 11 (121, 32) to y \n",
            "merge 12 (101, 110) to en\n",
            "merge 13 (111, 117) to ou\n",
            "merge 14 (111, 32) to o \n",
            "merge 15 (102, 32) to f \n",
            "merge 16 (111, 114) to or\n",
            "merge 17 (46, 32) to . \n",
            "merge 18 (101, 278) to eĖ\n",
            "merge 19 (111, 291) to oģ\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 36.074 s\n",
            "File: /tmp/ipykernel_18106/1318646580.py\n",
            "Function: profile_merge at line 4\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     4                                           def profile_merge(vocab, big_text_encoded_local, vocab_size):\n",
            "     5         1        700.0    700.0      0.0    num_merges = vocab_size - 256\n",
            "     6        21      17900.0    852.4      0.0    for i in range(num_merges):\n",
            "     7        20        1e+10    5e+08     28.1      _, most_frequent_pair, _ = get_pair_count(big_text_encoded_local)\n",
            "     8        20        3e+10    1e+09     71.9      merge(big_text_encoded_local, most_frequent_pair, idx=vocab_size)\n",
            "     9        20      24000.0   1200.0      0.0      vocab_size += 1\n",
            "    10        20     164800.0   8240.0      0.0      vocab[vocab_size] = ''.join(map(chr, most_frequent_pair))\n",
            "    11        20    3024600.0 151230.0      0.0      print(f\"merge {i} {most_frequent_pair} to {vocab[vocab_size]}\")\n",
            "    12                                           \n",
            "    13         1        100.0    100.0      0.0    return vocab"
          ]
        }
      ],
      "source": [
        "%load_ext line_profiler\n",
        "\n",
        "\n",
        "def profile_merge(vocab, big_text_encoded_local, vocab_size):\n",
        "  num_merges = vocab_size - 256\n",
        "  for i in range(num_merges):\n",
        "    _, most_frequent_pair, _ = get_pair_count(big_text_encoded_local)\n",
        "    merge(big_text_encoded_local, most_frequent_pair, idx=vocab_size)\n",
        "    vocab_size += 1\n",
        "    vocab[vocab_size] = ''.join(map(chr, most_frequent_pair))\n",
        "    print(f\"merge {i} {most_frequent_pair} to {vocab[vocab_size]}\")\n",
        "\n",
        "  return vocab\n",
        "\n",
        "\n",
        "vocab, vocab_size = init_vocab()\n",
        "\n",
        "%lprun -f profile_merge profile_merge(vocab, big_text_encoded, vocab_size=276)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "769057"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(big_text_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The line_profiler extension is already loaded. To reload it, use:\n",
            "  %reload_ext line_profiler\n",
            "merge 0 (97, 114) to ar\n",
            "merge 1 (32, 32) to   \n",
            "merge 2 (114, 101) to re\n",
            "merge 3 (283, 278) to ěĖ\n",
            "merge 4 (116, 105) to ti\n",
            "merge 5 (97, 280) to aĘ\n",
            "merge 6 (116, 290) to tĢ\n",
            "merge 7 (281, 103) to ęg\n",
            "merge 8 (283, 32) to ě \n",
            "merge 9 (97, 108) to al\n",
            "merge 10 (104, 105) to hi\n",
            "merge 11 (115, 116) to st\n",
            "merge 12 (97, 32) to a \n",
            "merge 13 (10, 10) to \n",
            "\n",
            "\n",
            "merge 14 (97, 279) to aė\n",
            "merge 15 (281, 32) to ę \n",
            "merge 16 (282, 32) to Ě \n",
            "merge 17 (101, 115) to es\n",
            "merge 18 (286, 32) to Ğ \n",
            "merge 19 (111, 109) to om\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 9.19021 s\n",
            "File: /tmp/ipykernel_18106/3118551585.py\n",
            "Function: profile_mergev2 at line 4\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     4                                           def profile_mergev2(vocab, big_text_encoded_local, vocab_size):\n",
            "     5         1        700.0    700.0      0.0    num_merges = vocab_size - 256\n",
            "     6        21      19600.0    933.3      0.0    for i in range(num_merges):\n",
            "     7        20 1397251000.0    7e+07     15.2      _, most_frequent_pair, _ = get_pair_countv2(big_text_encoded_local)\n",
            "     8        20 7789902400.0    4e+08     84.8      big_text_encoded_local = mergev2(big_text_encoded_local, most_frequent_pair, vocab_size)\n",
            "     9        20      33000.0   1650.0      0.0      vocab_size += 1\n",
            "    10        20     202500.0  10125.0      0.0      vocab[vocab_size] = ''.join(map(chr, most_frequent_pair))\n",
            "    11        20    2795900.0 139795.0      0.0      print(f\"merge {i} {most_frequent_pair} to {vocab[vocab_size]}\")"
          ]
        }
      ],
      "source": [
        "%load_ext line_profiler\n",
        "\n",
        "\n",
        "def profile_mergev2(vocab, big_text_encoded_local, vocab_size):\n",
        "  num_merges = vocab_size - 256\n",
        "  for i in range(num_merges):\n",
        "    _, most_frequent_pair, _ = get_pair_countv2(big_text_encoded_local)\n",
        "    big_text_encoded_local = mergev2(big_text_encoded_local, most_frequent_pair, vocab_size)\n",
        "    vocab_size += 1\n",
        "    vocab[vocab_size] = ''.join(map(chr, most_frequent_pair))\n",
        "    print(f\"merge {i} {most_frequent_pair} to {vocab[vocab_size]}\")\n",
        "\n",
        "vocab, vocab_size = init_vocab()\n",
        "%lprun -f profile_mergev2 profile_mergev2(vocab, big_text_encoded, vocab_size=276)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "769057"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(big_text_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The line_profiler extension is already loaded. To reload it, use:\n",
            "  %reload_ext line_profiler\n",
            "merge 0 (97, 114) to ar\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 1.91471 s\n",
            "File: /tmp/ipykernel_18106/3332047646.py\n",
            "Function: profile_mergev3 at line 4\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     4                                           def profile_mergev3(vocab, big_text_encoded_local, vocab_size):\n",
            "     5         1        700.0    700.0      0.0    num_merges = vocab_size - 256\n",
            "     6        21      13800.0    657.1      0.0    for i in range(num_merges):\n",
            "     7        20 1702466500.0    9e+07     88.9      _, most_frequent_pair, _ = get_paircountv3(big_text_encoded_local)\n",
            "     8        20  211881500.0    1e+07     11.1      big_text_encoded_local = mergev3(big_text_encoded_local, most_frequent_pair, vocab_size)\n",
            "     9        20      49900.0   2495.0      0.0      vocab_size += 1\n",
            "    10        20     197000.0   9850.0      0.0      vocab[vocab_size] = ''.join(map(chr, most_frequent_pair))\n",
            "    11        20      50200.0   2510.0      0.0      if i % 100 == 0:\n",
            "    12         1      46000.0  46000.0      0.0        print(f\"merge {i} {most_frequent_pair} to {vocab[vocab_size]}\")\n",
            "    13         1        300.0    300.0      0.0    return vocab"
          ]
        }
      ],
      "source": [
        "%load_ext line_profiler\n",
        "\n",
        "\n",
        "def profile_mergev3(vocab, big_text_encoded_local, vocab_size):\n",
        "  num_merges = vocab_size - 256\n",
        "  for i in range(num_merges):\n",
        "    _, most_frequent_pair, _ = get_paircountv3(big_text_encoded_local)\n",
        "    big_text_encoded_local = mergev3(big_text_encoded_local, most_frequent_pair, vocab_size)\n",
        "    vocab_size += 1\n",
        "    vocab[vocab_size] = ''.join(map(chr, most_frequent_pair))\n",
        "    if i % 100 == 0:\n",
        "      print(f\"merge {i} {most_frequent_pair} to {vocab[vocab_size]}\")\n",
        "  return vocab\n",
        "  \n",
        "\n",
        "vocab, vocab_size = init_vocab()\n",
        "%lprun -f profile_mergev3 profile_mergev3(vocab, big_text_encoded, vocab_size=276)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "merge 0 (97, 114) to ar\n",
            "merge 100 (97, 103) to ag\n",
            "merge 200 (1257, 32) to ө \n",
            "merge 300 (114, 97) to ra\n",
            "merge 400 (1427, 276) to ֓Ĕ\n",
            "merge 500 (1689, 276) to ڙĔ\n",
            "merge 600 (108, 121) to ly\n",
            "merge 700 (99, 1530) to c׺\n",
            "merge 800 (277, 1834) to ĕܪ\n",
            "merge 900 (1416, 1856) to ֈ݀\n",
            "merge 1000 (1516, 1374) to ׬՞\n"
          ]
        }
      ],
      "source": [
        "vocab, vocab_size = init_vocab()\n",
        "vocab = profile_mergev3(vocab, big_text_encoded, vocab_size=1257)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnAEaJPULOnL",
        "outputId": "6b81fd07-c96e-4c6a-8efe-77255d1f60b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reverse_vocab = {v: k for k, v in vocab.items()}\n",
        "max_token_size = max(map(len, reverse_vocab.keys()))\n",
        "max_token_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmARh_4gIg1A",
        "outputId": "bdb90dd5-75ca-45dc-dc64-e01c18077305"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[72, 1333, 1348, 32, 116, 1266, 115, 32, 1399, 32, 65, 106, 1516]\n",
            "Hello this is Ajay\n",
            "['H', 'el', 'lo', ' ', 't', 'hi', 's', ' ', 'is', ' ', 'A', 'j', 'ay']\n"
          ]
        }
      ],
      "source": [
        "def encode(text, reverse_vocab):\n",
        "  i = 0\n",
        "  text_encoded = []\n",
        "  while i < len(text):\n",
        "    for j in range(max_token_size, 0, -1):\n",
        "      potential_token = text[i:i+j]\n",
        "      if potential_token in reverse_vocab:\n",
        "        text_encoded.append(reverse_vocab[potential_token])\n",
        "        i += j\n",
        "        break\n",
        "  return text_encoded\n",
        "\n",
        "\n",
        "def decode(text_encoded, vocab):\n",
        "  text = \"\"\n",
        "  text_list = []\n",
        "  for code in text_encoded:\n",
        "    text += vocab[code]\n",
        "    text_list.append(vocab[code])\n",
        "  return text, text_list\n",
        "\n",
        "encoded_text = encode(\"Hello this is Ajay\", reverse_vocab)\n",
        "print(encoded_text)\n",
        "decoded_text, decoded_text_list = decode(encoded_text, vocab)\n",
        "print(decoded_text)\n",
        "print(decoded_text_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBVEPgODMv5-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOh1z8AfU1msFyB1A9Q2YbC",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "GPT2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
