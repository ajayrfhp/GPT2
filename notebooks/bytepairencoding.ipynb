{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajayrfhp/LearningDeepLearning/blob/main/bytepairencoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44FPA2fwh2l5"
      },
      "source": [
        "# Bytepair encoding\n",
        "- Goal is to reimplement bytepair encoding from scratch and have output match with the tiktoken library\n",
        "\n",
        "## GPT2 tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input string: Hello, world!\n",
            "GPT-2 tokenized: [15496, 11, 995, 0]\n",
            "GPT-2 tokenized intermediate: ['Hello', ',', ' world', '!']\n",
            "GPT-2 tokenized decoded: Hello, world!\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "\n",
        "input_str = \"Hello, world!\"\n",
        "gpt2_tokenizer = tiktoken.encoding_for_model(\"gpt-2\")\n",
        "gpt2_tokenized = gpt2_tokenizer.encode(input_str)\n",
        "gpt2_tokenized_intermediate = [gpt2_tokenizer.decode([token]) for token in gpt2_tokenized]\n",
        "gpt2_tokenized_decoded = gpt2_tokenizer.decode(gpt2_tokenized)\n",
        "\n",
        "print(\"Input string:\", input_str)\n",
        "print(\"GPT-2 tokenized:\", gpt2_tokenized)\n",
        "print(\"GPT-2 tokenized intermediate:\", gpt2_tokenized_intermediate)\n",
        "print(\"GPT-2 tokenized decoded:\", gpt2_tokenized_decoded)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- GPT 2 tokenizer has 50,000 merges and 256 unicode characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50257"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gpt2_tokenizer.n_vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Implementation from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prepare vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fRg3WCvahsOL",
        "outputId": "b2a041fd-6b68-41e3-c24c-6080962378d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "max_vocab_size = 50257 \n",
        "\n",
        "\n",
        "def init_vocab():\n",
        "  vocab = {}\n",
        "  vocab_size = 0\n",
        "\n",
        "  for chr_code in range(256):\n",
        "    vocab[chr_code] = chr(chr_code)\n",
        "    vocab_size += 1\n",
        "  return vocab, vocab_size\n",
        "\n",
        "vocab, vocab_size = init_vocab()\n",
        "len(vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Get pair count statistics\n",
        "- Merge common tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VffNrD9NiIh5",
        "outputId": "c9250410-3197-4ef8-ab68-958a19385bd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(72, 101)\n",
            "12\n",
            "9\n"
          ]
        }
      ],
      "source": [
        "def get_pair_count(text, counts=defaultdict(int)):\n",
        "  most_frequent_pair = None\n",
        "  most_frequent_pair_count = 0\n",
        "  for i in range(len(text)-1):\n",
        "    pair = tuple(text[i:i+2])\n",
        "    counts[pair] += 1\n",
        "    if counts[pair] > most_frequent_pair_count:\n",
        "      most_frequent_pair = pair\n",
        "      most_frequent_pair_count = counts[pair]\n",
        "  return counts, most_frequent_pair, most_frequent_pair_count\n",
        "\n",
        "text = \"Hello, world!\"\n",
        "text_encoded = text.encode('utf-8')\n",
        "pair_count, most_frequent_pair, most_frequent_pair_count = get_pair_count(text_encoded)\n",
        "print(most_frequent_pair)\n",
        "\n",
        "# Add symbol for most frequent pair in vocab and run encoding again to replace most frequent pair with new symbol.\n",
        "\n",
        "def merge(text_encoded, pair, idx):\n",
        "  i = 0\n",
        "  text_encoded_merged = []\n",
        "  while i < len(text_encoded):\n",
        "    if not text_encoded[i]:\n",
        "      continue\n",
        "    elif i + 1 < len(text_encoded) and text_encoded[i] == pair[0] and text_encoded[i+1] == pair[1]:\n",
        "      text_encoded_merged.append(idx)\n",
        "      i += 2\n",
        "    else:\n",
        "      text_encoded_merged.append(text_encoded[i])\n",
        "      i += 1\n",
        "  return text_encoded_merged\n",
        "\n",
        "text_encoded=[1, 2, 3, 4, 5, 5, 1, 2, 9,  9, 1, 2]\n",
        "print(len(text_encoded))\n",
        "text_encoded = merge(\n",
        "    text_encoded,\n",
        "    pair=[1, 2],\n",
        "    idx=10\n",
        ")\n",
        "print(len(text_encoded))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqkZgltiGShu"
      },
      "source": [
        "Grab big text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oce4qDNuF5Jn",
        "outputId": "ed7b8233-820f-4b20-b370-f0a7c05fc88b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "220288"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import requests\n",
        "import regex as re\n",
        "big_text_url = \"https://raw.githubusercontent.com/dscape/spell/refs/heads/master/test/resources/big.txt\"\n",
        "\n",
        "big_text = requests.get(big_text_url).text\n",
        "big_text = big_text[:1000000]\n",
        "gpt2_pattern = r\"\"\"'(?:[sdmt]|ll|ve|re)| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"\n",
        "compiled_pattern = re.compile(gpt2_pattern)\n",
        "big_text = re.findall(compiled_pattern, big_text)\n",
        "big_text_encoded = [ list(chunk.encode(\"utf-8\")) for chunk in big_text if chunk]\n",
        "big_text_encoded = [item for item in big_text_encoded if len(item) > 0]\n",
        "\n",
        "len(big_text_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "big_text_encoded[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Let's do 10 merges and profile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPi_poCuHlfv",
        "outputId": "6aca98b7-9679-41cb-8e21-3c23d8097dd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The line_profiler extension is already loaded. To reload it, use:\n",
            "  %reload_ext line_profiler\n",
            "[[84, 104, 101], [32, 80, 114, 111, 106, 101, 99, 116]]\n",
            "merge 1 (32, 116) to  t\n",
            "[[84, 277], [32, 80, 114, 111, 106, 101, 99, 116]]\n",
            "merge 2 (104, 101) to he\n",
            "[[84, 277], [32, 80, 114, 111, 106, 101, 99, 116]]\n",
            "merge 3 (32, 97) to  a\n",
            "[[84, 277], [32, 80, 114, 111, 106, 101, 99, 116]]\n",
            "merge 4 (105, 110) to in\n",
            "[[84, 277], [32, 80, 114, 111, 106, 101, 99, 116]]\n",
            "merge 5 (276, 277) to Ĕĕ\n",
            "[[84, 277], [32, 80, 114, 111, 106, 101, 99, 116]]\n",
            "merge 6 (32, 111) to  o\n",
            "[[84, 277], [32, 80, 114, 111, 106, 101, 99, 116]]\n",
            "merge 7 (114, 101) to re\n",
            "[[84, 277], [32, 80, 114, 111, 106, 101, 99, 116]]\n",
            "merge 8 (32, 119) to  w\n",
            "[[84, 277], [32, 80, 114, 111, 106, 101, 99, 116]]\n",
            "merge 9 (32, 115) to  s\n",
            "[[84, 277], [32, 80, 114, 111, 106, 101, 99, 116]]\n",
            "merge 10 (101, 114) to er\n",
            "[[84, 277], [32, 80, 114, 111, 106, 101, 99, 116]]\n",
            "merge 11 (111, 110) to on\n",
            "[[84, 277], [32, 80, 114, 111, 106, 101, 99, 116]]\n",
            "merge 12 (110, 100) to nd\n",
            "[[84, 277], [32, 80, 114, 111, 106, 101, 99, 116]]\n",
            "merge 13 (104, 97) to ha\n",
            "[[84, 277], [32, 80, 114, 111, 106, 101, 99, 116]]\n",
            "merge 14 (111, 117) to ou\n",
            "[[84, 277], [32, 80, 114, 111, 106, 101, 99, 116]]\n",
            "merge 15 (105, 115) to is\n",
            "[[84, 277], [32, 80, 114, 111, 106, 101, 99, 116]]\n",
            "merge 16 (101, 100) to ed\n",
            "[[84, 277], [32, 80, 114, 111, 106, 101, 99, 116]]\n",
            "merge 17 (105, 116) to it\n",
            "[[84, 277], [32, 80, 114, 111, 106, 101, 99, 116]]\n",
            "merge 18 (281, 102) to ęf\n",
            "[[84, 277], [32, 80, 114, 111, 106, 101, 99, 116]]\n",
            "merge 19 (101, 110) to en\n",
            "[[84, 277], [32, 80, 114, 111, 106, 101, 99, 116]]\n",
            "merge 20 (32, 99) to  c\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 44.1768 s\n",
            "File: /tmp/ipykernel_1151/2353498619.py\n",
            "Function: profile_merge at line 4\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     4                                           def profile_merge(vocab, big_text_encoded_local, vocab_size):\n",
            "     5         1       2100.0   2100.0      0.0    num_merges = vocab_size - 256\n",
            "     6         1        500.0    500.0      0.0    i = 0\n",
            "     7        21      13100.0    623.8      0.0    while i < num_merges:\n",
            "     8        20       5900.0    295.0      0.0      most_frequent_pair = None \n",
            "     9        20       5700.0    285.0      0.0      most_frequent_pair_count = 0\n",
            "    10        20    1175800.0  58790.0      0.0      counts = defaultdict(int)\n",
            "    11   4405780  990247800.0    224.8      2.2      for chunk in big_text_encoded_local:\n",
            "    12   4405760        2e+10   4274.7     42.6        counts, chunk_most_frequent_pair, chunk_most_frequent_pair_count = get_pair_count(chunk, counts)\n",
            "    13   4405760 1044722800.0    237.1      2.4        if chunk_most_frequent_pair_count > most_frequent_pair_count:\n",
            "    14    206129   43273700.0    209.9      0.1          most_frequent_pair = chunk_most_frequent_pair\n",
            "    15    206129   43148400.0    209.3      0.1          most_frequent_pair_count = chunk_most_frequent_pair_count\n",
            "    16                                               \n",
            "    17        20      19100.0    955.0      0.0      if most_frequent_pair:\n",
            "    18        20        2e+10    1e+09     52.6        big_text_encoded_local= [merge(chunk, most_frequent_pair, vocab_size) for chunk in big_text_encoded_local]\n",
            "    19        20    3408800.0 170440.0      0.0        print(big_text_encoded_local[:2])\n",
            "    20        20      34700.0   1735.0      0.0        vocab_size += 1\n",
            "    21        20     111500.0   5575.0      0.0        vocab[vocab_size] = ''.join(map(chr, most_frequent_pair))\n",
            "    22        20       6400.0    320.0      0.0        i += 1\n",
            "    23        20     461900.0  23095.0      0.0        print(f\"merge {i} {most_frequent_pair} to {vocab[vocab_size]}\")\n",
            "    24                                               else:\n",
            "    25                                                 print(\"No more pairs to merge.\")\n",
            "    26                                                 print(chunk)\n",
            "    27                                                 break\n",
            "    28                                           \n",
            "    29         1        200.0    200.0      0.0    return vocab"
          ]
        }
      ],
      "source": [
        "%load_ext line_profiler\n",
        "\n",
        "\n",
        "def profile_merge(vocab, big_text_encoded_local, vocab_size):\n",
        "  num_merges = vocab_size - 256\n",
        "  i = 0\n",
        "  while i < num_merges:\n",
        "    most_frequent_pair = None \n",
        "    most_frequent_pair_count = 0\n",
        "    counts = defaultdict(int)\n",
        "    for chunk in big_text_encoded_local:\n",
        "      counts, chunk_most_frequent_pair, chunk_most_frequent_pair_count = get_pair_count(chunk, counts)\n",
        "      if chunk_most_frequent_pair_count > most_frequent_pair_count:\n",
        "        most_frequent_pair = chunk_most_frequent_pair\n",
        "        most_frequent_pair_count = chunk_most_frequent_pair_count\n",
        "    \n",
        "    if most_frequent_pair:\n",
        "      big_text_encoded_local= [merge(chunk, most_frequent_pair, vocab_size) for chunk in big_text_encoded_local]\n",
        "      print(big_text_encoded_local[:2])\n",
        "      vocab_size += 1\n",
        "      vocab[vocab_size] = ''.join(map(chr, most_frequent_pair))\n",
        "      i += 1\n",
        "      print(f\"merge {i} {most_frequent_pair} to {vocab[vocab_size]}\")\n",
        "    else:\n",
        "      print(\"No more pairs to merge.\")\n",
        "      print(chunk)\n",
        "      break\n",
        "\n",
        "  return vocab\n",
        "\n",
        "\n",
        "vocab, vocab_size = init_vocab()\n",
        "\n",
        "%lprun -f profile_merge profile_merge(vocab, big_text_encoded.copy(), vocab_size=276)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- V2 with counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(len(big_text_encoded))\n",
        "\n",
        "from collections import Counter\n",
        "def get_pair_countv2(text, counts):\n",
        "    pair_iterator = zip(text, text[1:])\n",
        "\n",
        "    # update counts with pair_iterator\n",
        "    for pair in pair_iterator:\n",
        "        counts[pair] += 1\n",
        "\n",
        "    most_frequent_pair = counts.most_common(1)\n",
        "    return counts, most_frequent_pair[0][0], most_frequent_pair[0][1]\n",
        "\n",
        "text = \"Hello, world!\"\n",
        "text_encoded = text.encode('utf-8')\n",
        "pair_count, most_frequent_pair, most_frequent_pair_count = get_pair_countv2(text_encoded, counts=Counter())\n",
        "print(most_frequent_pair)\n",
        "\n",
        "def mergev2(text_encoded, pair, idx):\n",
        "    i = 0\n",
        "    new_text_encoded = []\n",
        "    while i < len(text_encoded):\n",
        "        if i+1 < len(text_encoded) and text_encoded[i] == pair[0] and text_encoded[i+1] == pair[1]:\n",
        "            new_text_encoded.append(idx)\n",
        "            i += 2\n",
        "        else:\n",
        "            new_text_encoded.append(text_encoded[i])\n",
        "            i += 1\n",
        "    del text_encoded\n",
        "    return new_text_encoded\n",
        "\n",
        "mergev2(\n",
        "    text_encoded=[1, 2, 3, 4, 5, 5, 1, 2, 1, 2],\n",
        "    pair=[1, 2],\n",
        "    idx=10\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext line_profiler\n",
        "\n",
        "\n",
        "def profile_mergev2(vocab, big_text_encoded_local, vocab_size):\n",
        "  num_merges = vocab_size - 256\n",
        "  i = 0\n",
        "  while i < num_merges:\n",
        "    most_frequent_pair = None \n",
        "    most_frequent_pair_count = 0\n",
        "    counts = Counter()\n",
        "    for chunk in big_text_encoded_local:\n",
        "      counts, chunk_most_frequent_pair, chunk_most_frequent_pair_count = get_pair_countv2(chunk, counts)\n",
        "      if chunk_most_frequent_pair_count > most_frequent_pair_count:\n",
        "        most_frequent_pair = chunk_most_frequent_pair\n",
        "        most_frequent_pair_count = chunk_most_frequent_pair_count\n",
        "    if most_frequent_pair:\n",
        "      big_text_encoded_local= [mergev2(chunk, most_frequent_pair, vocab_size) for chunk in big_text_encoded_local]\n",
        "      vocab_size += 1\n",
        "      vocab[vocab_size] = ''.join(map(chr, most_frequent_pair))\n",
        "      i += 1\n",
        "      print(f\"merge {i} {most_frequent_pair} to {vocab[vocab_size]}\")\n",
        "\n",
        "  return vocab\n",
        "\n",
        "vocab, vocab_size = init_vocab()\n",
        "%lprun -f profile_mergev2 profile_mergev2(vocab, big_text_encoded.copy(), vocab_size=276)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- V3 with cython?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The cython extension is already loaded. To reload it, use:\n",
            "  %reload_ext cython\n"
          ]
        }
      ],
      "source": [
        "%load_ext cython\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(72, 101)\n",
            "12\n",
            "9\n"
          ]
        }
      ],
      "source": [
        "%%cython\n",
        "from collections import defaultdict\n",
        "from libc.stdint cimport uint8_t\n",
        "\n",
        "def get_paircountv3(list text, counts=None):\n",
        "    if counts is None:\n",
        "        counts = defaultdict(int)\n",
        "    cdef int i\n",
        "    cdef tuple most_frequent_pair = None\n",
        "    cdef int most_frequent_pair_count = 0\n",
        "    cdef tuple pair\n",
        "    for i in range(len(text) - 1):\n",
        "        pair = (text[i], text[i + 1])\n",
        "        counts[pair] += 1\n",
        "        if counts[pair] > most_frequent_pair_count:\n",
        "            most_frequent_pair = pair\n",
        "            most_frequent_pair_count = counts[pair]\n",
        "    return counts, most_frequent_pair, most_frequent_pair_count\n",
        "\n",
        "def mergev3(list text_encoded, tuple pair, int idx):\n",
        "    cdef int i = 0\n",
        "    cdef list text_encoded_merged = []\n",
        "    while i < len(text_encoded):\n",
        "        if i + 1 < len(text_encoded) and text_encoded[i] == pair[0] and text_encoded[i + 1] == pair[1]:\n",
        "            text_encoded_merged.append(idx)\n",
        "            i += 2\n",
        "        else:\n",
        "            text_encoded_merged.append(text_encoded[i])\n",
        "            i += 1\n",
        "    return text_encoded_merged\n",
        "\n",
        "# Example usage\n",
        "text_encoded = [72, 101, 108, 108, 111, 44, 32, 119, 111, 114, 108, 100, 33]\n",
        "pair_count, most_frequent_pair, most_frequent_pair_count = get_paircountv3(text_encoded)\n",
        "print(most_frequent_pair)\n",
        "\n",
        "text_encoded = [1, 2, 3, 4, 5, 5, 1, 2, 9, 9, 1, 2]\n",
        "print(len(text_encoded))\n",
        "text_encoded = mergev3(\n",
        "    text_encoded,\n",
        "    pair=(1, 2),\n",
        "    idx=10\n",
        ")\n",
        "print(len(text_encoded))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The line_profiler extension is already loaded. To reload it, use:\n",
            "  %reload_ext line_profiler\n",
            "220288\n",
            "merge 1 (32, 116) to  t\n",
            "merge 2 (104, 101) to he\n",
            "merge 3 (32, 97) to  a\n",
            "merge 4 (105, 110) to in\n",
            "merge 5 (276, 277) to Ĕĕ\n",
            "merge 6 (32, 111) to  o\n",
            "merge 7 (114, 101) to re\n",
            "merge 8 (32, 119) to  w\n",
            "merge 9 (32, 115) to  s\n",
            "merge 10 (101, 114) to er\n",
            "merge 11 (111, 110) to on\n",
            "merge 12 (110, 100) to nd\n",
            "merge 13 (104, 97) to ha\n",
            "merge 14 (111, 117) to ou\n",
            "merge 15 (105, 115) to is\n",
            "merge 16 (101, 100) to ed\n",
            "merge 17 (105, 116) to it\n",
            "merge 18 (281, 102) to ęf\n",
            "merge 19 (101, 110) to en\n",
            "merge 20 (32, 99) to  c\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Timer unit: 1e-09 s\n",
            "\n",
            "Total time: 16.3104 s\n",
            "File: /tmp/ipykernel_1151/3884388159.py\n",
            "Function: profile_mergev3 at line 4\n",
            "\n",
            "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
            "==============================================================\n",
            "     4                                           def profile_mergev3(vocab, big_text_encoded_local, vocab_size):\n",
            "     5         1       1400.0   1400.0      0.0    num_merges = vocab_size - 256\n",
            "     6         1        400.0    400.0      0.0    i = 0\n",
            "     7        21      21100.0   1004.8      0.0    while i < num_merges:\n",
            "     8        20       8700.0    435.0      0.0      most_frequent_pair = None \n",
            "     9        20      17700.0    885.0      0.0      most_frequent_pair_count = 0\n",
            "    10        20    2627300.0 131365.0      0.0      counts = Counter()\n",
            "    11   4405780 1187578500.0    269.6      7.3      for chunk in big_text_encoded_local:\n",
            "    12   4405760 8176326000.0   1855.8     50.1        counts, chunk_most_frequent_pair, chunk_most_frequent_pair_count = get_paircountv3(chunk, counts)\n",
            "    13   4405760 1279449800.0    290.4      7.8        if chunk_most_frequent_pair_count > most_frequent_pair_count:\n",
            "    14    206129   49748700.0    241.3      0.3          most_frequent_pair = chunk_most_frequent_pair\n",
            "    15    206129   47398500.0    229.9      0.3          most_frequent_pair_count = chunk_most_frequent_pair_count\n",
            "    16        20      16000.0    800.0      0.0      if most_frequent_pair:\n",
            "    17        20 5563457000.0    3e+08     34.1        big_text_encoded_local= [mergev3(chunk, most_frequent_pair, vocab_size) for chunk in big_text_encoded_local]\n",
            "    18        20      73300.0   3665.0      0.0        vocab_size += 1\n",
            "    19        20     261600.0  13080.0      0.0        vocab[vocab_size] = ''.join(map(chr, most_frequent_pair))\n",
            "    20        20      10900.0    545.0      0.0        i += 1\n",
            "    21        20    3389100.0 169455.0      0.0        print(f\"merge {i} {most_frequent_pair} to {vocab[vocab_size]}\")\n",
            "    22                                           \n",
            "    23         1        300.0    300.0      0.0    return vocab"
          ]
        }
      ],
      "source": [
        "%load_ext line_profiler\n",
        "\n",
        "print(len(big_text_encoded))\n",
        "def profile_mergev3(vocab, big_text_encoded_local, vocab_size):\n",
        "  num_merges = vocab_size - 256\n",
        "  i = 0\n",
        "  while i < num_merges:\n",
        "    most_frequent_pair = None \n",
        "    most_frequent_pair_count = 0\n",
        "    counts = Counter()\n",
        "    for chunk in big_text_encoded_local:\n",
        "      counts, chunk_most_frequent_pair, chunk_most_frequent_pair_count = get_paircountv3(chunk, counts)\n",
        "      if chunk_most_frequent_pair_count > most_frequent_pair_count:\n",
        "        most_frequent_pair = chunk_most_frequent_pair\n",
        "        most_frequent_pair_count = chunk_most_frequent_pair_count\n",
        "    if most_frequent_pair:\n",
        "      big_text_encoded_local= [mergev3(chunk, most_frequent_pair, vocab_size) for chunk in big_text_encoded_local]\n",
        "      vocab_size += 1\n",
        "      vocab[vocab_size] = ''.join(map(chr, most_frequent_pair))\n",
        "      i += 1\n",
        "      print(f\"merge {i} {most_frequent_pair} to {vocab[vocab_size]}\")\n",
        "\n",
        "  return vocab\n",
        "  \n",
        "\n",
        "vocab, vocab_size = init_vocab()\n",
        "%lprun -f profile_mergev3 profile_mergev3(vocab, big_text_encoded.copy(), vocab_size=276)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab, vocab_size = init_vocab()\n",
        "vocab = profile_mergev3(vocab, big_text_encoded, vocab_size=1257)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnAEaJPULOnL",
        "outputId": "6b81fd07-c96e-4c6a-8efe-77255d1f60b2"
      },
      "outputs": [],
      "source": [
        "reverse_vocab = {v: k for k, v in vocab.items()}\n",
        "max_token_size = max(map(len, reverse_vocab.keys()))\n",
        "max_token_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmARh_4gIg1A",
        "outputId": "bdb90dd5-75ca-45dc-dc64-e01c18077305"
      },
      "outputs": [],
      "source": [
        "def encode(text, reverse_vocab):\n",
        "  i = 0\n",
        "  text_encoded = []\n",
        "  while i < len(text):\n",
        "    for j in range(max_token_size, 0, -1):\n",
        "      potential_token = text[i:i+j]\n",
        "      if potential_token in reverse_vocab:\n",
        "        text_encoded.append(reverse_vocab[potential_token])\n",
        "        i += j\n",
        "        break\n",
        "  return text_encoded\n",
        "\n",
        "\n",
        "def decode(text_encoded, vocab):\n",
        "  text = \"\"\n",
        "  text_list = []\n",
        "  for code in text_encoded:\n",
        "    text += vocab[code]\n",
        "    text_list.append(vocab[code])\n",
        "  return text, text_list\n",
        "\n",
        "encoded_text = encode(\"Hello this is Ajay\", reverse_vocab)\n",
        "print(encoded_text)\n",
        "decoded_text, decoded_text_list = decode(encoded_text, vocab)\n",
        "print(decoded_text)\n",
        "print(decoded_text_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBVEPgODMv5-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOh1z8AfU1msFyB1A9Q2YbC",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "GPT2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
