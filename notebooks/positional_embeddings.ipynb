{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positional embeddings\n",
    "\n",
    "## Why ?\n",
    "- Self attention model do not have inherent notion of position unlike RNNs. \n",
    "- Position, ordering matters in language. Same word in different order could mean different things. \n",
    "\n",
    "## Types of embeddings\n",
    "### Absolute positional embedding\n",
    "- Positional information is encoded through a trainable embedding matrix that converts integer positions into embedding vectors. \n",
    "- Different dimensions encode position information captured at different frequencies\n",
    "- Easy to implement with standard embedding layers. It has poor sequence length extrapolation because it lacks knowledge of relative positioning. \n",
    "\n",
    "### Fixed sinusoidal embedding \n",
    "- No learned parameters, fixed sin and cosine embedding. Extrapolates to longer sequences.\n",
    "\n",
    "### Relative positional embedding \n",
    "- Encodes relative distance between tokens rather than absolute positions. \n",
    "\n",
    "### Rotary positional embedding\n",
    "- Has both relative and absolute positions. \n",
    "\n",
    "\n",
    "## Resources\n",
    "- GO through https://huggingface.co/blog/designing-positional-encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello my name is Ajay\n",
      "[15496, 616, 1438, 318, 22028, 323]\n",
      "torch.Size([1, 5])\n",
      "tensor([[[-0.7183,  0.0627],\n",
      "         [-0.6489,  1.2228],\n",
      "         [ 0.7233, -0.0964],\n",
      "         [-0.4918,  0.6275],\n",
      "         [-0.1155, -0.1441]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 50257\n",
    "embedding_dim = 2\n",
    "max_context_length = 5\n",
    "\n",
    "input_text = \"Hello my name is Ajay\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "print(input_text)\n",
    "\n",
    "input_tokens = tokenizer.encode(input_text)\n",
    "print(input_tokens)\n",
    "\n",
    "input_tensor = torch.tensor(input_tokens[:max_context_length]).unsqueeze(0)\n",
    "print(input_tensor.shape)\n",
    "\n",
    "token_embedding_layer = nn.Embedding(vocab_size, embedding_dim)\n",
    "input_embedding = token_embedding_layer(input_tensor)\n",
    "\n",
    "print(input_embedding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Absolute positional embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of absolute position embedding vector: torch.Size([1, 5, 2])\n",
      "tensor([[[ 0.7474, -0.4037],\n",
      "         [-0.2403, -1.0787],\n",
      "         [ 0.7312,  0.1028],\n",
      "         [ 0.0545,  0.0521],\n",
      "         [ 0.6613,  0.8048]]], grad_fn=<EmbeddingBackward0>)\n",
      "Shape of input plus absolute position embedding: torch.Size([1, 5, 2])\n",
      "tensor([[[ 0.0291, -0.3410],\n",
      "         [-0.8892,  0.1441],\n",
      "         [ 1.4545,  0.0065],\n",
      "         [-0.4373,  0.6796],\n",
      "         [ 0.5458,  0.6607]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "absolute_position_embedding_layer = nn.Embedding(max_context_length, embedding_dim)\n",
    "\n",
    "absolute_position_embedding = absolute_position_embedding_layer(torch.arange(max_context_length).unsqueeze(0))\n",
    "\n",
    "print(f\"Shape of absolute position embedding vector: {absolute_position_embedding.shape}\")\n",
    "\n",
    "print(absolute_position_embedding)\n",
    "\n",
    "input_plus_absolute_position_embedding = input_embedding + absolute_position_embedding\n",
    "\n",
    "print(f\"Shape of input plus absolute position embedding: {input_plus_absolute_position_embedding.shape}\")\n",
    "\n",
    "print(input_plus_absolute_position_embedding)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPT2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
